---
title: 《PhotoP Studio 开发日志 01》- 开启空间修图全新体验
date: 2024-12-15 19:36:15
tags:
---

![](../images/2024/photop_studio_0.png)

有没有想过有一天可以在空间中修图？用眼前 100 寸的大屏幕可以把你拍的照片细节放大到像素点贴脸去看，仅需用自己的手和眼就可以对关键参数进行调整！是的，我做了一个空间修图版的 PhotoP Studio！如果你也有 Vision Pro 的话，快来[开启全新体验](https://apps.apple.com/cn/app/photop-studio/id6739296926?l=en-GB)！



## 纠结
不知道大家兴不兴奋，当看到果子把历年来的 framework 和理念最终都汇集到一个产品上时，我觉得宛如是“神物降临”，让我看到了未来几年甚至十几年里人类对科技感受形态的变化，对参与时代进步的载体更迭，我逢人都说 Vision Pro 就是曾经我们想要的那个 iPhone，但那个具体的“iPhone 时刻”我与绝大部分人直观感受是一样的，至少在这一代产品上是来不到的。

因此不管是北美开卖还是国行开卖后我都没有第一时间去购买，甚至都没有去预约线下体验，不是不想要，我甚至在今年年初过完年后在看飞圣何塞的机票，脑子一热想着直接飞过去买一台带回来，甚至还有想找朋友圈的小伙伴买一台的冲动，后面还动了去咸鱼上找贩子买的心思，但这一切都因为遮光罩尺寸和近视镜片的限制全部作罢。随着时间的推移，工作上的事情也逐渐白热化忙了起来，买一个自己的 Vision Pro 这件事在几次扫描脸部信息后反复删除反复下单中遗忘。

一切的转机是发生在 10 月 22 日去参加一个骑车小伙伴的聚餐，刚好约在西单附近，我到的比较早，刚好也就顺路先去西单 apple store 逛逛消磨时间。这一逛就马上把我原本早已遗忘掉 Vision Pro 的心给复燃了起来，我专门走到 Vision Pro 的展柜附近，摸了摸不可移动的它，还去负一层看到了正在体验的顾客，看着他们那时而兴奋时而微笑藏在 Vision Pro 下的脸时，当时就给我整高兴了，我两眼放光的随便找到了一个 apple 员工，跟他表示出了我因为近视而多次放弃购买的意愿，她提醒我说你下次有空的话，可以直接预约来店里先使用，我们可以根据你的眼镜度数来匹配体验时的镜片，可以多来几次感受体验体验。我听到这句话后就记下了，在饭局上跟大家说起这件事，有小伙伴虽然说出了大家都懂的好像没啥用，但也有小伙伴说如果你本身对拿出买一台 Vision Pro 这三万块并不敏感，那就不用纠结，早买早享受。这句话也刺激到了我，因为我之前纠结的地方在于镜片，而不是价格，但就是因为被镜片拦了一道才觉得价格虚高，才会去找很多借口很多理由让自己不要去买，但我一直都清楚自己内心是十分想要，十分渴望的。

因此在接下来的时间里，我一到周末出去玩耍拍照时，在回家地铁上就顺路绕道最近的 apple store 预约体验 Vision Pro。第一次确实非常惊艳，不管是眼手搭配这种新奇的交互方式还是整体的 visionOS，都给人一种全新的彻底的变化，尤其是那个恐龙，从原本的画面中跃出并冲你吼叫的那一瞬间，我是真的被吓到，但沉浸式视频的体验不管是之前在 PICO 还是这次 Vision Pro 上都不够完美，首先是清晰度，其次是眼睛不舒服，总觉得眼睛压力很大。

前后总共体验了两次，网上的各种评测没少看，基本上属于每天一有空就会开始琢磨的状态，大家几乎一水的倒向“压脸”这一个缺点，我好像还没有见到没人说不压脸的。压脸说白了其实就前面配重过重，而且就算是双圈头带也无济于事，最佳的方案其实就应该照着 PICO 和 Quest 学，从顶部拉一根线穿过头顶，可以非常好的缓解压脸问题，但不知道为啥现在一些三方头戴都是通过侧边的两个耳机处往上拉，我觉得跟官方的双圈头带没有本质区别，还是不舒服。

但除此之外的其他问题我都不觉得是问题，甚至看的越多越兴奋，总觉得自己该入局该下场该上桌了，虽然可以预判到未来的两到三年买的用的人依旧不多，但在 Vision Pro 出现之前没有任何一台设备可以达到如此的体验。我之前只用过 PICO 4，而且还是因为司龄原因免费送的，从尝鲜角度来看花两三千元不管是买 PICO 还是 Quest 都已经完全足够了，但它仅仅只是尝鲜，而且二者本质上跑的都是 andriod，虽然外观整体看上去很玩具很廉价，但系统本身更廉价更玩具更没有让人使用的欲望，因此就算是免费送我的 PICO 4，最终还是被我卖掉了，整体的感受下来真的很难有每天使用的欲望。

最终我纠结了好几个晚上，甚至半夜翻身惊醒脑子里迅速想起的第一件事也是我可以在 Vision Pro 上做什么好玩的事情，每天早上坐在马桶上都在刷 Vision Pro 的消息，我知道自己如果不买的话，只会更纠结更痛苦，而且这本身就可以打开一个全新的大门学习全新的技术栈，除了价格外对于我来说确实没有任何缺点，遂在 11 月 20 日，一个周五的晚上，18 点一到就冲往西单 apple store 买了我朝思暮想的 Apple Vision Pro！

## 想法
拿到 Vision Pro 的那一天中午我就已经外卖下单好了隐形眼镜，但因为到家只剩下几个小时时间就要睡觉了，因此我就眯着眼用了晚上那几个小时，录制好了我的 persona 后就马上和薄桑、妈咪通了个 facetime 的视频，这种体验真的很神奇很新鲜，拖着大家的脸在屋子里晃荡，用 Vision Pro 拍出来的空间照片特别震撼，尤其是把小猫咪抱起来放在 Vision Pro 前面，拍下一张空间照片，回看的时候真的有种错觉。就算是我眼前模糊不清，Vision Pro 给我那天晚上的震撼现在回想起来都津津有味。

第二天我就尝试给自己戴隐形眼镜，很不幸的是失败了，第一个因为没有用镊子导致用手捏出来弄脏了，怎么都怼不进眼球，第二个有镊子了却被夹破了，第三个好不容易镊子把握好了力度，但因为眨眼的时候没弄好掉地上了，一盒五个隐形眼镜只剩下了最后两个，在女票的帮助下终于入眼成功！那一天玩的是真爽，不管是游戏还是应用基本上把能体验的都体验了一遍，整体看下来还是十分惊喜十分满意的，但可能是因为使用到的这些 app 没有超出太多预期，导致我内心其实是有一点点小失落的，总觉得还可以更好，还可以更接近实际场景一些。再加上我当场之所以想要买 Vision Pro 就是为了它的生产力场景，至于游戏之类的内容我权当是礼品相送，因此我一直都在尝试如何把它融入到自己现有的工作流重。

比较可惜的是，当 mac 投屏到 Vision Pro 占据的是 mac 自身“随航”协议接口，导致 iPhone 无法再投屏到 mac 上，如果不把 iPhone 投屏到 mac 上，透过 Vision Pro 去看环境里的 iPhone 屏幕是非常模糊的，我自己认为是无法使用的，因此至少是 iOS 开发这一点无法把 Vision Pro 这一点融入工作中来，其他倒是还好，比如前段时间做的 TranslateP 和这次的 PhotoP Studio，都是通过 Vision Pro 完成的。

经历了前面几天 Vision Pro 的尝鲜体验期过后我就一直在找自己可以通过什么样的切入点先做一些东西熟悉熟悉 visionOS 的开发流程，思来想去也看了不少东西，最终决定还是通过做一个 visionOS 版本的 PhotoP 来练手。原因是因为在 visionOS app 有三种表现形态，分别是 Window、Volume 和 Spaces，其中 Window 类型的 app 与在其他平台上几乎一样，可以使用完全一样的接口完全一样的思维去完成，只是需要兼容一些手势操作，本质上没有太大区别。反而 Volume 和 Spaces 类型的 app 都直接切换到了 3D 场景上，首先我是完全没有 3D 思维的，目前的我是完全不清楚如何去制作一个 3D 资源，如何把制作好的资源导入 app 中，如何显示如何交互等等，对于我来说如果一下从 2D 平面开发流程直接切换到 3D 空间空间开发流程我是完全无法接受的，甚至会因为打击过大而自暴自弃。对于一个全新的技术栈来说，快速建立技术自信心是一件非常重要的事情，直接决定了未来的我是否会继续投入精力。

因此我果断的选择了重写 PhotoP，做一个 visionOS 版本的空间修图 app，不管是从前面说的快速建立技术自信心，还是补一块在 Vision Pro 上缺失的拼图，都是一个收益极大的事情。


## 开发过程
从 11 月 20 日拿到 Vision Pro 开始到昨天，总算是把 PhotoP 给重写并迁移到了 visionOS 上，之所以是重写而不是兼容完全是因为 visionOS 的整体架构是“移动端”而不是“桌面端”，无法使用 macOS 的 API（比如 AppKit），但却可以无缝使用 UIKit 甚至是运行 iPadOS 和 iOS 的所有 app，如果大家仔细观察的话，会发现在 visionOS 上放大窗口的 UI 和交互设计来自 iPad OS，甚至在它上面的 Safari 都是 iPadOS 的模样，可以说果子先通过在 iPadOS 上注入未来可能的交互，让大家先有一部分熟悉习惯，后续再复制到其他平台上轻而易举。

所以我需要重写而不是兼容，但好在 SwiftUI 的多平台兼容性，除了入口视图的改造外，其他的内容我几乎可以一行不改的全部导入 visionOS 工程直接使用，大大减少了重写成本。虽然 SwiftUI 就是 visionOS 的原生开发框架，但前两天 setapp 发布一个 2024 年度总结里，就连 macOS 这种历史包袱这么重的平台也有将近一半的开发者会选择使用 SwiftUI 进行开发。仔细想想好像也是，从两年前我就已经开始使用 SwiftUI 在 macOS 上写出了 PhotoP，再加上前段时间的 TranslateP，可以说把 SwiftUI 融合进各自的开发流程中只会加速而不是拖累。也比较期待当明年剪映工程可以升级到最低支持 iOS 13 后爽写 SwiftUI 的场景了。

这里我还是需要再次宣传一次 SwiftUI，因为 SwiftUI 的开发思路完全不像 UIKit 或者 AppKit 那样需要有那么重的成本，需要开发者进行精雕细琢很久才能看到最终的效果，我觉得首先是 SwiftUI API 的统一性，只要你写过一次学习过一次理解过一次，就可以完全放心大胆的在任何支持 SwiftUI 的平台去使用它，完全不需要担心统一性，换来的只是便利性和比之前更小的心智负担。但缺点也是在此了，如果想要通过 SwiftUI 做一些与其他人不同的差异化设计，如果对 API 不熟悉设计得不够完善，可能花费的时间并不一定比之前使用 UIKit 时短。经过这次的开发过程再次领略到了这点，如果我们只是按照果子的常规 app 设计去做每一步，非常快，一晚上可以框框干出好多东西，但拿 PhotoP 特色的滑杆来说，我两年前和两年后居然写出了两套逻辑，虽然核心逻辑都是复用的，但就滑块本身因为思维的变化，居然能有不同的写法，也都达到了一样的效果，挺有意思。

本身 PhotoP 是强依赖 Metal 版本的 GPUImage 框架，刚好 Metal 也是全平台 API 兼容，与 SwiftUI 相同也是仅需写一次学习一次就可以处处运行，但因为 Vision Pro 当前针对普通消费者购买的版本没有开放摄像头画面捕捉权限，无法使用 AVCapture 相关的 API，需要我们把 GPUImage 里关于 AVCapture 相关代码都注释掉，但没必要删除，因为如果是商业版本的 Vision Pro 反而是可以有这个权限的，换句话说就是不管你的 Vision Pro 是不是国行都是残血版，我很期待下一代或者未来版本的 Vision Pro 可以下放摄像头权限，开发者一定可以做出更酷炫的产品！

因为毕竟是要运行在 visionOS 上的 app 嘛，别说真实用户了就算是我自己都会下意识的在点开其他 app 后用空间手势这里点点那里拖拖，甚至是放大、旋转这种手势都会顺手来上这么几下，因此在 PhotoP 里支持空间手势就成为了一个必须要做的事情。我原本以为在 visionOS app 里支持空间手势会比较复杂，但没想到居然也只需使用原本的在 macOS 上的手势识别器即可，除非是有诉求需要识别类似蜘蛛侠发射蛛丝，或者类似 apple 开发者网站里示例 demo 一样的爱心手势，需要借助 ARKit 框架能力单独根据手部关节位置的距离等条件进行额外判断，除此之外，我们在 visionOS 上是可以完全复用系统手势，完全不需要写任何兼容逻辑就可以完成的。我开心快乐的就是在 PhotoP 上加上了双击、长按和双手拖拽的手势，让整体可玩性又上了一个台阶。

这次我还用到了一个 [VisionPanel](https://github.com/reftonull/VisionPanes) 这个三方库，我觉得作者的思路非常有意思，具体的使用上也非常有趣，我引入后直接让 PhotoP 的可玩性上了一个台阶。用户需要点击一个按钮或者随便一个什么入口，从而触发上下左右四个方向的面板展示，如果不需要的话展示面板的话，就只用主面板就好，我觉得这个思路太棒了！在推特上刷到后马上就引入了 PhotoP 中，只用用户选择“编辑”，调色面板才会展出，否则 PhotoP 在 visionOS 就是一个巨大的图片查看器，这点很简约，改造完毕后我觉得非常好。

冲着这个“图片查看器”的思路，我昨天早上原本是打算支持一波展示空间照片的，原本以为只是调一个 API 打开显示这么简单，但没想的自定义空间照片的现实居然会如此的麻烦， 不但要替换掉 PhotoP 底层的渲染容器，全部改为 AVPlayerView 相关类型去支持，还要处理很多空间照片的数据流转，思来想去总觉得还是过于麻烦了，而且很有可能就算我支持展示后，也会破坏掉原本的修图渲染链路，感觉得不偿失。再加上我仔细看了系统相册，居然还真的没有对空间照片放出“编辑”入口，我觉得官方应该是遇到了一些问题，我觉得还是期待一波，也就作罢。

大概是这周三晚上左右，我把 PhotoP 的 test flight 版本发布了，没想到居然半小时就过了！按照 TranslateP 的经验第一次审核是至少一天的，没想到如此的快速，更神奇的是在昨天晚上 21:06 进审，21:39 就过审了！感觉果子一定是针对 visionOS 做了单独的审核链路，跟其他平台的差距也太大了。

## 未来规划
在可预期的未来里，是需要针对 PhotoP 加上 Spaces 类型场景，进入沉浸式模式的，要不然怎么能叫 Studio 呢！大概的想法也有了，我要做一个识别左手手背的功能板，当识别到用户的左手手背后就会在手背上方出现一个功能板，提供更丰富自由度更大的参数调节，甚至可以延伸到整个左手手臂，使用用户的手臂作为功能区入口，面前就是一个巨大的画布，除了修图外还可以做比如添加文字、加贴纸、自定义画笔等高阶功能，写到这里又开始热血沸腾了！

但除了 PhotoP Studio 这种确定性打满的产品外，这周末其实耗费最多时间精力的是星球罐子的 visionOS 版本，如果说近期我最期待的下一个产品是什么，无疑就是星球罐子的 visionOS 版本，虽然星球罐子已经是七年半之前的产品了，前段时间把它再次重新上架，剔除 cocoapods 依赖的各种库外，还能无缝编译起来感受到了 OC 稳定性的震撼外，我一直都很期待能够真正的把大家带入星球罐子设定的世界里，去感受当初我看“爱死机”，做星球罐子时所感受到的那种深空的无力感。

比较可惜的是，上面也有说到一些，就是我完全没有 3D 开发思维，就昨天才折腾出了一个圆形球体的贴图和无限循环自转动画，这么简单的一个操作，我都折腾了这么久，有点梦回大一那会熬夜开发“大学+”自己这个第一款 iOS app，深夜去各个 iOS 开发群里找各个大佬问如何自定义 UINavigationBar 的返回按钮 icon，那会真的是头秃到爆炸，折腾了一天完全没有版本基于系统标准实现自定义返回按钮，后来才知道，业界的实现都是自己做的一个假导航栏视图贴到顶部，隐藏掉了系统自带的。当初知道这个细节后那时的我真的是差点一口老血喷涌而出，完全没往这方面想过。

现在的我跟那时的我十分类似。我先是在 Reality Composer Pro 中轻松的创建出了一个球体，也顺利的加上了材质贴图，但让这个球体旋转起来居然差点折腾了一晚上，AI 工具针对这种非 coding 场景而是 UI 操作是完全帮不上忙的，回答得牛头不对马嘴，最后还是翻到了一个说法，说 RCP 里针对动画的实现不完整，还是推荐到 blender 中做好后导出，看到这个内容后我马上打开 blender，看了些教程后，十几分钟就搞定了。由此可见，在可预期的未来很长一段时间里我还要不停的踩一些切换技术栈学习新技术过程中必要的坑，而且一定会相当痛苦，反复折磨。

但一想到可以自己的星球罐子最终成品运行在 visionOS 上那震撼壮丽的景象，总觉得现在的一切是值得的！总之期待吧！

visionOS App Store：[https://apps.apple.com/cn/app/photop-studio/id6739296926?l=en-GB](https://apps.apple.com/cn/app/photop-studio/id6739296926?l=en-GB)